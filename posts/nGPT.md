---
title: "Normalized Transformer"
subtitle: ""
author: "Aakash Kumar Nain ([@A_K_Nain](https://x.com/A_K_Nain))"
date: "2024-10-23"
categories: [papers, summary, transformers, research]
image: ""
format:
  html:
    code-fold: true
    code-summary: "Show the code"
    highlight-style: oblivion
execute: 
  echo: false
---

We have been using transformers daily for a couple of years now, but the advancements on the architectural side have remained minimal. This paper from Nvidia proposes a **normalized Transformer (nGPT)**, which performs representation learning on a hypersphere. Here is a summary for the same:


**Token embeddings and output logits**

1. Both input and output embedding matrices are normalized after each training step.
2. The logits are bounded in the range [-1, 1] because of the normalization, which limits the confidence of the probability distribution generated by the softmax.
3. To adjust this during training, the authors introduce a trainable scaling parameter *sz* that scales the logits element-wise.



**Layers and Blocks** 
- A typical transformer block looks like this where L layers of transformations are applied to the hidden state h, consisting of alternating the self-attention and MLP blocks: